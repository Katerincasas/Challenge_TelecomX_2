{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-Jz6ncJ3xu1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TelecomX - Parte 2: Predicción de Churn con Machine Learning\n",
        "\n",
        "## Misión del Proyecto\n",
        "\n",
        "¡Bienvenida al equipo de Machine Learning de TelecomX!\n",
        "\n",
        "Como Analista Junior de Machine Learning, mi misión en este proyecto es desarrollar modelos predictivos robustos para identificar qué clientes tienen mayor probabilidad de cancelar sus servicios. De esta manera, la empresa podrá anticiparse al problema de churn y tomar decisiones estratégicas para retener a sus clientes.\n",
        "\n",
        "## Objetivos del Challenge\n",
        "\n",
        "- Preparar los datos para el modelado (tratamiento, codificación, normalización).\n",
        "- Realizar análisis de correlación y seleccionar las variables más relevantes.\n",
        "- Entrenar al menos cuatro modelos de clasificación diferentes.\n",
        "- Evaluar el rendimiento de los modelos utilizando métricas completas.\n",
        "- Interpretar los resultados y analizar la importancia de las variables.\n",
        "- Proponer conclusiones estratégicas para la retención de clientes.\n",
        "\n",
        "> **Nota:** Si es la primera vez que ejecutas este notebook, instala las dependencias necesarias con:\n",
        ">\n",
        "> ```\n",
        "> pip install -r requirements.txt\n",
        "> ```\n"
      ],
      "metadata": {
        "id": "Flqjhjna3ycX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importación de librerías necesarias\n",
        "print(\"Importando librerías para Machine Learning...\")\n",
        "\n",
        "# Verificar e importar librerías básicas\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import json\n",
        "    import warnings\n",
        "    warnings.filterwarnings('ignore')\n",
        "    print(\" Pandas, NumPy: OK\")\n",
        "except ImportError as e:\n",
        "    print(f\" Error importando librerías básicas: {e}\")\n",
        "\n",
        "# Visualización\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    print(\" Matplotlib, Seaborn: OK\")\n",
        "except ImportError as e:\n",
        "    print(f\" Error: {e}\")\n",
        "\n",
        "try:\n",
        "    import plotly.express as px\n",
        "    import plotly.graph_objects as go\n",
        "    from plotly.subplots import make_subplots\n",
        "    print(\" Plotly: OK\")\n",
        "except ImportError as e:\n",
        "    print(f\" Plotly no disponible: {e}\")\n",
        "    print(\"Instala con: pip install plotly\")\n",
        "\n",
        "# Machine Learning\n",
        "try:\n",
        "    from sklearn.model_selection import train_test_split, cross_val_score\n",
        "    from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    from sklearn.svm import SVC\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "    from sklearn.metrics import (\n",
        "        accuracy_score, precision_score, recall_score, f1_score,\n",
        "        confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "    )\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "    print(\" Scikit-learn: OK\")\n",
        "except ImportError as e:\n",
        "    print(f\"Error importando sklearn: {e}\")\n",
        "\n",
        "# Balanceo de clases (opcional)\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    smote_available = True\n",
        "    print(\"SMOTE (imbalanced-learn): OK\")\n",
        "except ImportError:\n",
        "    smote_available = False\n",
        "    print(\"SMOTE no disponible - se usarán class_weights\")\n",
        "\n",
        "# Configuración\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "print(\"\\n¡Librerías importadas exitosamente!\")\n",
        "print(\"Listo para entrenar modelos de Machine Learning\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5otZpXJ30Jf",
        "outputId": "8af000d6-6914-4d54-c60f-9f37eca87861"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importando librerías para Machine Learning...\n",
            " Pandas, NumPy: OK\n",
            " Matplotlib, Seaborn: OK\n",
            " Plotly: OK\n",
            " Scikit-learn: OK\n",
            "SMOTE (imbalanced-learn): OK\n",
            "\n",
            "¡Librerías importadas exitosamente!\n",
            "Listo para entrenar modelos de Machine Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PASO 2: Carga de datos**\n",
        "\n"
      ],
      "metadata": {
        "id": "x45cx37w35cm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "oosBGdUF2MZ9"
      },
      "source": [
        "En esta sección cargaremos los datos desde el archivo JSON y los prepararemos para Machine Learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LdRZw_BV33we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PASO 3: Preprocesamiento y selección de variables**"
      ],
      "metadata": {
        "id": "CYio0HwQ4CQn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "28jd0qGn4H0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PASO 4: División de datos en entrenamiento y prueba**"
      ],
      "metadata": {
        "id": "bfFZXhjy4Inm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qKRGlDfW4OHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PASO 5: Entrenamiento de modelos**"
      ],
      "metadata": {
        "id": "ZAa38FPs4Ope"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2-vGX3C4UWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PASO 6: Evaluación de modelos**"
      ],
      "metadata": {
        "id": "Vjjr_SBY4fb2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T-M8r66b4jQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PASO 7: Análisis de importancia de variables**"
      ],
      "metadata": {
        "id": "o31s-xce46n9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sypxM2Mc339u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mhzmu9XH4-Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4uXGTj3a34Ie"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}